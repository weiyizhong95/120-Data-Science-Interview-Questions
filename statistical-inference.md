## Statistical Inference (15 questions)

#### 1. In an A/B test, how can you check if assignment to the various buckets was truly random?
 
 
#### 2. What might be the benefits of running an A/A test, where you have two buckets who are exposed to the exact same product?
  
  
#### 3. What would be the hazards of letting users sneak a peek at the other bucket in an A/B test?


#### 4. What would be some issues if blogs decide to cover one of your experimental groups?
 
 
#### 5. How would you conduct an A/B test on an opt-in feature? 
  
  
#### 6. How would you run an A/B test for many variants, say 20 or more?


#### 7. How would you run an A/B test if the observations are extremely right-skewed?
 

#### 8. I have two different experiments that both change the sign-up button to my website. I want to test them at the same time. What kinds of things should I keep in mind?


#### 9. What is a p-value? What is the di erence between type-1 and type-2 error?
 
 
#### 10. You are AirBnB and you want to test the hypothesis that a greater number of photographs increases the chances that a buyer selects the listing. How would you test this hypothesis?


#### 11. How would you design an experiment to determine the impact of latency on user engagement?


#### 12. What is maximum likelihood estimation? Could there be any case where it doesn’t exist?


#### 13. What’s the di erence between a MAP, MOM, MLE estima\- tor? In which cases would you want to use each?

 
#### 14. What is a confidence interval and how do you interpret it?


#### 15. What is unbiasedness as a property of an estimator? Is this always a desirable property when performing inference? What about in data analysis or predictive modeling?


